{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "No XP for this. Just some warmup work to introduce convolutional neural networks.\n",
    "\n",
    "## A guided tour\n",
    "\n",
    "Let's first practice what we learned in the first Keras Python Notebook\n",
    "\n",
    "## 1. Load the MNIST Dataset\n",
    "First let's load the MNIST dataset from Keras into Numpy arrays called:\n",
    "\n",
    "     train_images, train_labels, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2. Reshape the Data\n",
    "In the first notebook we reshaped the data into\n",
    "\n",
    "     (60000, 28 * 28)\n",
    "     \n",
    "Basically, we flattened the image. For this notebook let's retain the 2D structure and reshape it:\n",
    "\n",
    "     ((60000, 28, 28, 1))\n",
    "     \n",
    "At the same time we should also set the type to be `float32`\n",
    "\n",
    "At the end of this step you should have new values for `train_images` and `test_images`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Categorically Encode the Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating the Model - The ConvNet layers\n",
    "This part I will give to you now and explain during class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Adding Layers\n",
    "Now we need to flatten the outputs of the ConvNet layers to the 1D representation our classifier needs.\n",
    "The classification layer will be exactly the same as that in the first notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# ADD CLASSIFICATION LAYER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compile the Model\n",
    "Now it is time to compile the model. Use the same optimizer, loss function, and accuracy metrics we used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Fit the Model to the Training Data\n",
    "Use 5 epochs and a batch size of 64. Don't forget to save the history. We will also use the `fit` parameter `validation_split`. Here is what the Keras documentation says about it: \n",
    "\n",
    "> validation_split: Float between 0 and 1. Fraction of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch. The validation data is selected from the last samples in the x and y data provided, before shuffling.\n",
    "\n",
    "Let's use a validation split of 0.2\n",
    "\n",
    "Once you start training help others in your team get to this point.  Once your whole team is at this step let me know so I can start talking about the details of ConvNets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Run the Model on The Test Data\n",
    "Run the Model on the Test Data and print the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Graph The Loss and Accuracy\n",
    "Let's use Matplotlib to plot the training and validation loss side by side, as well as the training and validation accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Question?\n",
    "Compared to the network we built in the first Keras Notebook, did we reduce the error rate by 1/4, 1/3, 1/2, 3/4?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. The End / Download Data\n",
    "That's it for this notebook but remember to download the cat and dog dataset before Friday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
